{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Dataset Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as p\n",
    "import cedalion.datasets\n",
    "import cedalion.plots\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score,roc_curve, roc_auc_score, auc\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy.stats import pointbiserialr\n",
    "from scipy.stats import binom\n",
    "from classify_utils_old import plot_grouped_bars_by_subject, plot_grouped_bars_by_dt, loso_classification, extract_features, parcel_loso_classification, get_parcel_loso_features\n",
    "\n",
    "import cedalion_parcellation\n",
    "import cedalion_parcellation.datasets\n",
    "import cedalion_parcellation.plots\n",
    "import cedalion_parcellation.imagereco.forward_model as fw\n",
    "from cedalion.imagereco.solver import pseudo_inverse_stacked\n",
    "import configs\n",
    "from configs import load_dataset_configs\n",
    "\n",
    "import cedalion.geometry.landmarks as cd_landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = configs.data_path_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_significant_correct(n, p=0.5, alpha=0.05):\n",
    "    print(n)\n",
    "    print(next(k for k in range(n + 1) if binom.sf(k - 1, n, p) < alpha))\n",
    "    return next(k for k in range(n + 1) if binom.sf(k - 1, n, p) < alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_types = ['HD_Squeezing', 'BS_Laura']\n",
    "dataset_configs = load_dataset_configs(data_types=data_types, load_sensitivity=True, test=True)\n",
    "shared_parcel_subset = [p for p in dataset_configs['HD_Squeezing'].sensitive_parcels]\n",
    "#dataset_configs = load_dataset_configs(data_types=data_types)\n",
    "#shared_parcel_subset = [p for p in dataset_configs['HD_Squeezing'][\"sensitive_parcels\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(shared_parcel_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_path, 'BS_Laura', 'subsets_data'), 'rb') as file:\n",
    "    subsets_data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract LOSO Features for both datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing HD_Squeezing dataset... \n",
      "\n",
      "SUBSETS\n",
      "{'full': {'n_optodes': 46, 'n_optodes_percent': 100.0, 'all': ['S1D1', 'S1D2', 'S1D4', 'S1D5', 'S1D6', 'S1D8', 'S2D2', 'S2D3', 'S2D5', 'S2D6', 'S2D7', 'S2D9', 'S3D1', 'S3D4', 'S3D5', 'S3D8', 'S3D10', 'S3D11', 'S3D14', 'S4D2', 'S4D4', 'S4D5', 'S4D6', 'S4D7', 'S4D8', 'S4D9', 'S4D10', 'S4D11', 'S4D12', 'S4D13', 'S4D15', 'S5D3', 'S5D6', 'S5D7', 'S5D9', 'S5D12', 'S5D13', 'S5D16', 'S6D8', 'S6D10', 'S6D11', 'S6D12', 'S6D14', 'S6D15', 'S7D9', 'S7D11', 'S7D12', 'S7D13', 'S7D15', 'S7D16', 'S8D17', 'S8D18', 'S8D20', 'S8D21', 'S8D22', 'S8D24', 'S9D18', 'S9D19', 'S9D21', 'S9D22', 'S9D23', 'S9D25', 'S10D17', 'S10D20', 'S10D21', 'S10D24', 'S10D26', 'S10D27', 'S10D30', 'S11D18', 'S11D20', 'S11D21', 'S11D22', 'S11D23', 'S11D24', 'S11D25', 'S11D26', 'S11D27', 'S11D28', 'S11D29', 'S11D31', 'S12D19', 'S12D22', 'S12D23', 'S12D25', 'S12D28', 'S12D29', 'S12D32', 'S13D24', 'S13D26', 'S13D27', 'S13D28', 'S13D30', 'S13D31', 'S14D25', 'S14D27', 'S14D28', 'S14D29', 'S14D31', 'S14D32'], 'all_percent': 100.0, 'long': ['S1D6', 'S1D8', 'S2D5', 'S2D9', 'S3D1', 'S3D5', 'S3D11', 'S3D14', 'S4D2', 'S4D4', 'S4D7', 'S4D10', 'S4D13', 'S4D15', 'S5D3', 'S5D6', 'S5D12', 'S5D16', 'S6D8', 'S6D12', 'S7D9', 'S7D11', 'S8D22', 'S8D24', 'S9D21', 'S9D25', 'S10D17', 'S10D21', 'S10D27', 'S10D30', 'S11D18', 'S11D20', 'S11D23', 'S11D26', 'S11D29', 'S11D31', 'S12D19', 'S12D22', 'S12D28', 'S12D32', 'S13D24', 'S13D28', 'S14D25', 'S14D27'], 'long_percent': 100.0, 'short': ['S1D1', 'S1D2', 'S1D4', 'S1D5', 'S2D2', 'S2D3', 'S2D6', 'S2D7', 'S3D4', 'S3D8', 'S3D10', 'S4D5', 'S4D6', 'S4D8', 'S4D9', 'S4D11', 'S4D12', 'S5D7', 'S5D9', 'S5D13', 'S6D10', 'S6D11', 'S6D14', 'S6D15', 'S7D12', 'S7D13', 'S7D15', 'S7D16', 'S8D17', 'S8D18', 'S8D20', 'S8D21', 'S9D18', 'S9D19', 'S9D22', 'S9D23', 'S10D20', 'S10D24', 'S10D26', 'S11D21', 'S11D22', 'S11D24', 'S11D25', 'S11D27', 'S11D28', 'S12D23', 'S12D25', 'S12D29', 'S13D26', 'S13D27', 'S13D30', 'S13D31', 'S14D28', 'S14D29', 'S14D31', 'S14D32']}, 'subset_1': {'n_optodes': 38, 'n_optodes_percent': 82.61, 'all': ['S1D1', 'S1D2', 'S1D5', 'S1D6', 'S1D8', 'S2D2', 'S2D3', 'S2D5', 'S2D6', 'S2D9', 'S3D1', 'S3D5', 'S3D8', 'S3D11', 'S3D14', 'S4D2', 'S4D5', 'S4D6', 'S4D8', 'S4D9', 'S4D11', 'S4D12', 'S4D15', 'S5D3', 'S5D6', 'S5D9', 'S5D12', 'S5D16', 'S6D8', 'S6D11', 'S6D12', 'S6D14', 'S6D15', 'S7D9', 'S7D11', 'S7D12', 'S7D15', 'S7D16', 'S8D17', 'S8D18', 'S8D21', 'S8D22', 'S8D24', 'S9D18', 'S9D19', 'S9D21', 'S9D22', 'S9D25', 'S10D17', 'S10D21', 'S10D24', 'S10D27', 'S10D30', 'S11D18', 'S11D21', 'S11D22', 'S11D24', 'S11D25', 'S11D27', 'S11D28', 'S11D31', 'S12D19', 'S12D22', 'S12D25', 'S12D28', 'S12D32', 'S13D24', 'S13D27', 'S13D28', 'S13D30', 'S13D31', 'S14D25', 'S14D27', 'S14D28', 'S14D31', 'S14D32'], 'all_percent': 76.0, 'long': ['S1D6', 'S1D8', 'S2D5', 'S2D9', 'S3D1', 'S3D5', 'S3D11', 'S3D14', 'S4D2', 'S4D15', 'S5D3', 'S5D6', 'S5D12', 'S5D16', 'S6D8', 'S6D12', 'S7D9', 'S7D11', 'S8D22', 'S8D24', 'S9D21', 'S9D25', 'S10D17', 'S10D21', 'S10D27', 'S10D30', 'S11D18', 'S11D31', 'S12D19', 'S12D22', 'S12D28', 'S12D32', 'S13D24', 'S13D28', 'S14D25', 'S14D27'], 'long_percent': 81.82, 'short': ['S1D1', 'S1D2', 'S1D5', 'S2D2', 'S2D3', 'S2D6', 'S3D8', 'S4D5', 'S4D6', 'S4D8', 'S4D9', 'S4D11', 'S4D12', 'S5D9', 'S6D11', 'S6D14', 'S6D15', 'S7D12', 'S7D15', 'S7D16', 'S8D17', 'S8D18', 'S8D21', 'S9D18', 'S9D19', 'S9D22', 'S10D24', 'S11D21', 'S11D22', 'S11D24', 'S11D25', 'S11D27', 'S11D28', 'S12D25', 'S13D27', 'S13D30', 'S13D31', 'S14D28', 'S14D31', 'S14D32']}, 'subset_2': {'n_optodes': 30, 'n_optodes_percent': 65.22, 'all': ['S1D1', 'S1D2', 'S1D8', 'S2D2', 'S2D3', 'S2D9', 'S3D1', 'S3D8', 'S3D14', 'S4D2', 'S4D8', 'S4D9', 'S4D15', 'S5D3', 'S5D9', 'S5D16', 'S6D8', 'S6D14', 'S6D15', 'S7D9', 'S7D15', 'S7D16', 'S8D17', 'S8D18', 'S8D24', 'S9D18', 'S9D19', 'S9D25', 'S10D17', 'S10D24', 'S10D30', 'S11D18', 'S11D24', 'S11D25', 'S11D31', 'S12D19', 'S12D25', 'S12D32', 'S13D24', 'S13D30', 'S13D31', 'S14D25', 'S14D31', 'S14D32'], 'all_percent': 44.0, 'long': ['S1D8', 'S2D9', 'S3D1', 'S3D14', 'S4D2', 'S4D15', 'S5D3', 'S5D16', 'S6D8', 'S7D9', 'S8D24', 'S9D25', 'S10D17', 'S10D30', 'S11D18', 'S11D31', 'S12D19', 'S12D32', 'S13D24', 'S14D25'], 'long_percent': 45.45, 'short': ['S1D1', 'S1D2', 'S2D2', 'S2D3', 'S3D8', 'S4D8', 'S4D9', 'S5D9', 'S6D14', 'S6D15', 'S7D15', 'S7D16', 'S8D17', 'S8D18', 'S9D18', 'S9D19', 'S10D24', 'S11D24', 'S11D25', 'S12D25', 'S13D30', 'S13D31', 'S14D31', 'S14D32']}, 'subset_3': {'n_optodes': 12, 'n_optodes_percent': 26.09, 'all': ['S1D8', 'S2D9', 'S6D8', 'S7D9', 'S8D24', 'S9D25', 'S13D24', 'S14D25'], 'all_percent': 8.0, 'long': ['S1D8', 'S2D9', 'S6D8', 'S7D9', 'S8D24', 'S9D25', 'S13D24', 'S14D25'], 'long_percent': 18.18, 'short': []}}\n",
      "/home/thomas/Dokumente/Master/Master_Thesis/HD-DOT Classification/data/HD_Squeezing/epochs_labels/test/sub-170/run0_epochs_labels.pkl\n",
      "/home/thomas/Dokumente/Master/Master_Thesis/HD-DOT Classification/data/HD_Squeezing/epochs_labels/test/sub-170/run1_epochs_labels.pkl\n",
      "/home/thomas/Dokumente/Master/Master_Thesis/HD-DOT Classification/data/HD_Squeezing/epochs_labels/test/sub-170/run2_epochs_labels.pkl\n",
      "/home/thomas/Dokumente/Master/Master_Thesis/HD-DOT Classification/data/HD_Squeezing/epochs_labels/test/sub-173/run0_epochs_labels.pkl\n",
      "/home/thomas/Dokumente/Master/Master_Thesis/HD-DOT Classification/data/HD_Squeezing/epochs_labels/test/sub-173/run1_epochs_labels.pkl\n",
      "/home/thomas/Dokumente/Master/Master_Thesis/HD-DOT Classification/data/HD_Squeezing/epochs_labels/test/sub-173/run2_epochs_labels.pkl\n",
      "/home/thomas/Dokumente/Master/Master_Thesis/HD-DOT Classification/data/HD_Squeezing/epochs_labels/test/sub-174/run0_epochs_labels.pkl\n",
      "/home/thomas/Dokumente/Master/Master_Thesis/HD-DOT Classification/data/HD_Squeezing/epochs_labels/test/sub-174/run1_epochs_labels.pkl\n",
      "/home/thomas/Dokumente/Master/Master_Thesis/HD-DOT Classification/data/HD_Squeezing/epochs_labels/test/sub-174/run2_epochs_labels.pkl\n",
      "/home/thomas/Dokumente/Master/Master_Thesis/HD-DOT Classification/data/HD_Squeezing/epochs_labels/test/sub-176/run0_epochs_labels.pkl\n",
      "/home/thomas/Dokumente/Master/Master_Thesis/HD-DOT Classification/data/HD_Squeezing/epochs_labels/test/sub-176/run1_epochs_labels.pkl\n",
      "/home/thomas/Dokumente/Master/Master_Thesis/HD-DOT Classification/data/HD_Squeezing/epochs_labels/test/sub-176/run2_epochs_labels.pkl\n",
      "/home/thomas/Dokumente/Master/Master_Thesis/HD-DOT Classification/data/HD_Squeezing/epochs_labels/test/sub-177/run0_epochs_labels.pkl\n",
      "/home/thomas/Dokumente/Master/Master_Thesis/HD-DOT Classification/data/HD_Squeezing/epochs_labels/test/sub-177/run1_epochs_labels.pkl\n",
      "/home/thomas/Dokumente/Master/Master_Thesis/HD-DOT Classification/data/HD_Squeezing/epochs_labels/test/sub-177/run2_epochs_labels.pkl\n",
      "/home/thomas/Dokumente/Master/Master_Thesis/HD-DOT Classification/data/HD_Squeezing/epochs_labels/test/sub-179/run0_epochs_labels.pkl\n",
      "/home/thomas/Dokumente/Master/Master_Thesis/HD-DOT Classification/data/HD_Squeezing/epochs_labels/test/sub-179/run1_epochs_labels.pkl\n",
      "/home/thomas/Dokumente/Master/Master_Thesis/HD-DOT Classification/data/HD_Squeezing/epochs_labels/test/sub-179/run2_epochs_labels.pkl\n",
      "/home/thomas/Dokumente/Master/Master_Thesis/HD-DOT Classification/data/HD_Squeezing/epochs_labels/test/sub-181/run0_epochs_labels.pkl\n",
      "/home/thomas/Dokumente/Master/Master_Thesis/HD-DOT Classification/data/HD_Squeezing/epochs_labels/test/sub-181/run1_epochs_labels.pkl\n",
      "/home/thomas/Dokumente/Master/Master_Thesis/HD-DOT Classification/data/HD_Squeezing/epochs_labels/test/sub-181/run2_epochs_labels.pkl\n",
      "/home/thomas/Dokumente/Master/Master_Thesis/HD-DOT Classification/data/HD_Squeezing/epochs_labels/test/sub-182/run0_epochs_labels.pkl\n",
      "/home/thomas/Dokumente/Master/Master_Thesis/HD-DOT Classification/data/HD_Squeezing/epochs_labels/test/sub-182/run1_epochs_labels.pkl\n",
      "/home/thomas/Dokumente/Master/Master_Thesis/HD-DOT Classification/data/HD_Squeezing/epochs_labels/test/sub-182/run2_epochs_labels.pkl\n",
      "/home/thomas/Dokumente/Master/Master_Thesis/HD-DOT Classification/data/HD_Squeezing/epochs_labels/test/sub-183/run0_epochs_labels.pkl\n",
      "/home/thomas/Dokumente/Master/Master_Thesis/HD-DOT Classification/data/HD_Squeezing/epochs_labels/test/sub-183/run1_epochs_labels.pkl\n",
      "/home/thomas/Dokumente/Master/Master_Thesis/HD-DOT Classification/data/HD_Squeezing/epochs_labels/test/sub-183/run2_epochs_labels.pkl\n",
      "/home/thomas/Dokumente/Master/Master_Thesis/HD-DOT Classification/data/HD_Squeezing/epochs_labels/test/sub-185/run0_epochs_labels.pkl\n",
      "/home/thomas/Dokumente/Master/Master_Thesis/HD-DOT Classification/data/HD_Squeezing/epochs_labels/test/sub-185/run1_epochs_labels.pkl\n",
      "/home/thomas/Dokumente/Master/Master_Thesis/HD-DOT Classification/data/HD_Squeezing/epochs_labels/test/sub-185/run2_epochs_labels.pkl\n",
      "\n",
      "Feature type: Slope \n",
      "\n",
      "\n",
      "Pruning channels: True \n",
      "\n",
      "\n",
      "Feature reduction: False \n",
      "\n",
      "biggest subset size:  100\n",
      "parcel subset size:  104\n",
      "\n",
      "Processing BS_Laura dataset... \n",
      "\n",
      "SUBSETS\n",
      "{'full': {'n_optodes': 200, 'n_optodes_percent': 100.0, 'all': ['S1D34', 'S1D36', 'S1D38', 'S1D39', 'S1D65', 'S1D67', 'S1D69', 'S2D34', 'S2D36', 'S2D38', 'S2D138', 'S2D140', 'S2D142', 'S2D144', 'S3D37', 'S3D38', 'S3D39', 'S3D40', 'S3D65', 'S3D66', 'S3D67', 'S3D68', 'S3D69', 'S3D70', 'S3D71', 'S3D72', 'S4D33', 'S4D34', 'S4D35', 'S4D36', 'S4D37', 'S4D38', 'S4D39', 'S4D40', 'S4D65', 'S4D142', 'S4D143', 'S4D144', 'S5D33', 'S5D34', 'S5D95', 'S5D96', 'S5D137', 'S5D138', 'S5D139', 'S5D140', 'S5D141', 'S5D142', 'S5D143', 'S5D144', 'S6D1', 'S6D3', 'S6D17', 'S6D18', 'S6D20', 'S6D40', 'S6D66', 'S6D68', 'S6D70', 'S6D71', 'S6D129', 'S6D130', 'S7D17', 'S7D33', 'S7D35', 'S7D37', 'S7D39', 'S7D40', 'S7D66', 'S7D68', 'S7D129', 'S7D130', 'S7D134', 'S8D33', 'S8D35', 'S8D37', 'S8D129', 'S8D130', 'S8D134', 'S8D135', 'S8D139', 'S8D141', 'S8D143', 'S8D144', 'S9D92', 'S9D94', 'S9D96', 'S9D133', 'S9D134', 'S9D135', 'S9D136', 'S9D137', 'S9D139', 'S9D141', 'S9D143', 'S10D85', 'S10D87', 'S10D89', 'S10D90', 'S10D92', 'S10D94', 'S10D96', 'S10D112', 'S10D133', 'S10D135', 'S10D136', 'S11D82', 'S11D83', 'S11D85', 'S11D87', 'S11D89', 'S11D102', 'S11D104', 'S11D110', 'S11D111', 'S11D112', 'S11D136', 'S12D88', 'S12D89', 'S12D90', 'S12D91', 'S12D92', 'S12D93', 'S12D94', 'S12D95', 'S12D96', 'S12D137', 'S12D138', 'S12D139', 'S13D81', 'S13D82', 'S13D83', 'S13D84', 'S13D85', 'S13D86', 'S13D87', 'S13D88', 'S13D89', 'S13D90', 'S13D91', 'S13D92', 'S14D91', 'S14D93', 'S14D95', 'S14D137', 'S14D138', 'S14D140', 'S14D142', 'S15D84', 'S15D86', 'S15D88', 'S15D90', 'S15D91', 'S15D93', 'S15D95', 'S16D81', 'S16D83', 'S16D84', 'S16D86', 'S16D88', 'S16D101', 'S16D103', 'S17D79', 'S17D82', 'S17D97', 'S17D99', 'S17D100', 'S17D102', 'S17D104', 'S17D110', 'S17D111', 'S17D112', 'S17D128', 'S18D74', 'S18D76', 'S18D113', 'S18D115', 'S18D117', 'S18D118', 'S18D120', 'S18D125', 'S18D126', 'S18D127', 'S18D128', 'S19D74', 'S19D76', 'S19D77', 'S19D79', 'S19D97', 'S19D99', 'S19D111', 'S19D120', 'S19D125', 'S19D127', 'S19D128', 'S20D81', 'S20D82', 'S20D83', 'S20D84', 'S20D85', 'S20D98', 'S20D99', 'S20D100', 'S20D101', 'S20D102', 'S20D103', 'S20D104', 'S21D73', 'S21D74', 'S21D75', 'S21D76', 'S21D77', 'S21D78', 'S21D79', 'S21D116', 'S21D117', 'S21D118', 'S21D119', 'S21D120', 'S22D75', 'S22D76', 'S22D77', 'S22D78', 'S22D79', 'S22D80', 'S22D97', 'S22D98', 'S22D99', 'S22D100', 'S22D101', 'S22D102', 'S23D78', 'S23D80', 'S23D81', 'S23D98', 'S23D100', 'S23D101', 'S23D103', 'S24D73', 'S24D75', 'S24D77', 'S24D78', 'S24D80', 'S24D98', 'S24D119', 'S25D6', 'S25D8', 'S25D10', 'S25D12', 'S25D13', 'S25D15', 'S25D18', 'S25D19', 'S25D28', 'S25D31', 'S25D41', 'S26D1', 'S26D3', 'S26D5', 'S26D6', 'S26D8', 'S26D10', 'S26D17', 'S26D18', 'S26D19', 'S26D20', 'S26D71', 'S27D3', 'S27D4', 'S27D5', 'S27D6', 'S27D7', 'S27D8', 'S27D9', 'S27D10', 'S27D11', 'S27D12', 'S27D13', 'S27D14', 'S28D10', 'S28D11', 'S28D12', 'S28D13', 'S28D14', 'S28D15', 'S28D16', 'S28D41', 'S28D42', 'S28D43', 'S28D44', 'S28D45', 'S29D1', 'S29D2', 'S29D3', 'S29D4', 'S29D5', 'S29D6', 'S29D7', 'S29D68', 'S29D69', 'S29D70', 'S29D71', 'S29D72', 'S30D7', 'S30D9', 'S30D11', 'S30D12', 'S30D14', 'S30D16', 'S30D42', 'S31D2', 'S31D4', 'S31D5', 'S31D7', 'S31D9', 'S31D11', 'S31D72', 'S32D2', 'S32D4', 'S32D65', 'S32D67', 'S32D69', 'S32D70', 'S32D72', 'S33D49', 'S33D51', 'S33D52', 'S33D54', 'S33D60', 'S33D62', 'S33D64', 'S34D45', 'S34D47', 'S34D57', 'S34D58', 'S34D60', 'S34D62', 'S34D64', 'S35D14', 'S35D16', 'S35D42', 'S35D43', 'S35D45', 'S35D47', 'S35D57', 'S36D48', 'S36D49', 'S36D50', 'S36D51', 'S36D57', 'S36D58', 'S36D59', 'S36D60', 'S36D61', 'S36D62', 'S36D63', 'S36D64', 'S37D41', 'S37D42', 'S37D43', 'S37D44', 'S37D45', 'S37D46', 'S37D47', 'S37D48', 'S37D57', 'S37D58', 'S37D59', 'S37D60', 'S38D25', 'S38D26', 'S38D27', 'S38D49', 'S38D50', 'S38D53', 'S38D59', 'S38D61', 'S38D63', 'S38D121', 'S38D126', 'S39D26', 'S39D27', 'S39D28', 'S39D44', 'S39D46', 'S39D48', 'S39D58', 'S39D59', 'S39D61', 'S39D63', 'S39D121', 'S40D13', 'S40D15', 'S40D19', 'S40D27', 'S40D28', 'S40D31', 'S40D41', 'S40D43', 'S40D44', 'S40D46', 'S40D48', 'S41D55', 'S41D73', 'S41D75', 'S41D114', 'S41D116', 'S41D118', 'S41D119', 'S42D51', 'S42D52', 'S42D54', 'S42D55', 'S42D56', 'S42D114', 'S42D116', 'S43D25', 'S43D49', 'S43D50', 'S43D51', 'S43D52', 'S43D53', 'S43D54', 'S43D55', 'S43D56', 'S43D63', 'S43D64', 'S43D113', 'S44D53', 'S44D54', 'S44D55', 'S44D56', 'S44D113', 'S44D114', 'S44D115', 'S44D116', 'S44D117', 'S44D118', 'S44D119', 'S44D120', 'S45D25', 'S45D50', 'S45D53', 'S45D56', 'S45D113', 'S45D115', 'S45D117', 'S45D121', 'S45D126', 'S45D127', 'S46D97', 'S46D104', 'S46D105', 'S46D106', 'S46D107', 'S46D108', 'S46D109', 'S46D110', 'S46D111', 'S46D112', 'S46D124', 'S46D125', 'S46D127', 'S46D128', 'S47D25', 'S47D26', 'S47D29', 'S47D109', 'S47D115', 'S47D121', 'S47D123', 'S47D124', 'S47D125', 'S47D126', 'S47D127', 'S48D32', 'S48D105', 'S48D106', 'S48D107', 'S48D108', 'S48D109', 'S48D122', 'S48D123', 'S48D124', 'S48D125', 'S49D23', 'S49D24', 'S49D26', 'S49D29', 'S49D30', 'S49D32', 'S49D106', 'S49D122', 'S49D123', 'S49D124', 'S50D19', 'S50D23', 'S50D26', 'S50D27', 'S50D28', 'S50D29', 'S50D30', 'S50D31', 'S50D32', 'S50D46', 'S50D61', 'S50D121', 'S50D123', 'S51D21', 'S51D24', 'S51D105', 'S51D106', 'S51D107', 'S51D108', 'S51D122', 'S51D131', 'S51D132', 'S51D133', 'S52D87', 'S52D94', 'S52D105', 'S52D106', 'S52D107', 'S52D108', 'S52D110', 'S52D111', 'S52D112', 'S52D131', 'S52D132', 'S52D133', 'S52D135', 'S52D136', 'S53D8', 'S53D15', 'S53D17', 'S53D18', 'S53D19', 'S53D20', 'S53D21', 'S53D22', 'S53D23', 'S53D24', 'S53D28', 'S53D30', 'S53D31', 'S53D32', 'S54D35', 'S54D129', 'S54D130', 'S54D131', 'S54D132', 'S54D133', 'S54D134', 'S54D135', 'S54D136', 'S54D141', 'S55D20', 'S55D21', 'S55D22', 'S55D23', 'S55D24', 'S55D32', 'S55D105', 'S55D122', 'S55D129', 'S55D131', 'S56D1', 'S56D17', 'S56D18', 'S56D20', 'S56D21', 'S56D22', 'S56D66', 'S56D129', 'S56D130', 'S56D134'], 'all_percent': 100.0, 'long': ['S1D34', 'S1D39', 'S1D69', 'S2D38', 'S2D138', 'S2D144', 'S3D37', 'S3D38', 'S3D66', 'S3D67', 'S3D71', 'S3D72', 'S4D35', 'S4D36', 'S4D40', 'S4D65', 'S4D142', 'S4D143', 'S5D33', 'S5D34', 'S5D95', 'S5D96', 'S5D140', 'S5D141', 'S6D3', 'S6D18', 'S6D20', 'S6D40', 'S6D70', 'S6D129', 'S6D130', 'S7D17', 'S7D33', 'S7D39', 'S7D68', 'S7D129', 'S7D134', 'S8D37', 'S8D129', 'S8D130', 'S8D135', 'S8D139', 'S8D144', 'S9D92', 'S9D133', 'S9D134', 'S9D136', 'S9D137', 'S9D143', 'S10D85', 'S10D90', 'S10D96', 'S10D112', 'S10D133', 'S10D135', 'S11D83', 'S11D89', 'S11D102', 'S11D110', 'S11D111', 'S11D136', 'S12D88', 'S12D89', 'S12D93', 'S12D94', 'S12D138', 'S12D139', 'S13D81', 'S13D82', 'S13D86', 'S13D87', 'S13D91', 'S13D92', 'S14D91', 'S14D137', 'S14D142', 'S15D84', 'S15D90', 'S15D95', 'S16D83', 'S16D88', 'S16D101', 'S17D79', 'S17D82', 'S17D100', 'S17D110', 'S17D112', 'S17D128', 'S18D76', 'S18D113', 'S18D118', 'S18D125', 'S18D126', 'S18D128', 'S19D77', 'S19D99', 'S19D111', 'S19D120', 'S19D125', 'S19D127', 'S20D84', 'S20D85', 'S20D98', 'S20D99', 'S20D103', 'S20D104', 'S21D73', 'S21D74', 'S21D78', 'S21D79', 'S21D116', 'S21D117', 'S22D75', 'S22D76', 'S22D80', 'S22D97', 'S22D101', 'S22D102', 'S23D78', 'S23D81', 'S23D100', 'S24D77', 'S24D98', 'S24D119', 'S25D6', 'S25D12', 'S25D18', 'S25D28', 'S25D31', 'S25D41', 'S26D5', 'S26D10', 'S26D17', 'S26D19', 'S26D20', 'S26D71', 'S27D3', 'S27D4', 'S27D8', 'S27D9', 'S27D13', 'S27D14', 'S28D10', 'S28D11', 'S28D15', 'S28D16', 'S28D44', 'S28D45', 'S29D1', 'S29D2', 'S29D6', 'S29D7', 'S29D68', 'S29D69', 'S30D7', 'S30D12', 'S30D42', 'S31D5', 'S31D11', 'S31D72', 'S32D4', 'S32D65', 'S32D70', 'S33D49', 'S33D54', 'S33D60', 'S34D45', 'S34D58', 'S34D64', 'S35D14', 'S35D43', 'S35D57', 'S36D48', 'S36D50', 'S36D51', 'S36D57', 'S36D61', 'S36D62', 'S37D41', 'S37D42', 'S37D46', 'S37D47', 'S37D59', 'S37D60', 'S38D26', 'S38D27', 'S38D49', 'S38D53', 'S38D59', 'S38D126', 'S39D26', 'S39D28', 'S39D44', 'S39D58', 'S39D63', 'S39D121', 'S40D13', 'S40D19', 'S40D27', 'S40D31', 'S40D43', 'S40D48', 'S41D55', 'S41D75', 'S41D118', 'S42D51', 'S42D56', 'S42D116', 'S43D25', 'S43D52', 'S43D55', 'S43D63', 'S43D64', 'S43D113', 'S44D53', 'S44D54', 'S44D114', 'S44D115', 'S44D119', 'S44D120', 'S45D50', 'S45D56', 'S45D117', 'S45D121', 'S45D127', 'S46D97', 'S46D104', 'S46D105', 'S46D106', 'S46D107', 'S46D112', 'S46D124', 'S46D127', 'S47D25', 'S47D26', 'S47D29', 'S47D109', 'S47D115', 'S47D121', 'S47D125', 'S47D127', 'S48D32', 'S48D105', 'S48D107', 'S48D108', 'S48D123', 'S48D125', 'S49D23', 'S49D24', 'S49D26', 'S49D30', 'S49D106', 'S49D124', 'S50D19', 'S50D23', 'S50D32', 'S50D46', 'S50D61', 'S50D121', 'S50D123', 'S51D21', 'S51D24', 'S51D106', 'S51D107', 'S51D108', 'S51D122', 'S51D133', 'S52D87', 'S52D94', 'S52D105', 'S52D106', 'S52D108', 'S52D111', 'S52D131', 'S52D135', 'S53D8', 'S53D15', 'S53D17', 'S53D21', 'S53D24', 'S53D28', 'S53D30', 'S53D32', 'S54D35', 'S54D130', 'S54D132', 'S54D136', 'S54D141', 'S55D20', 'S55D23', 'S55D32', 'S55D105', 'S55D122', 'S55D129', 'S55D131', 'S56D1', 'S56D18', 'S56D22', 'S56D66', 'S56D134'], 'long_percent': 100.0, 'short': ['S1D36', 'S1D38', 'S1D65', 'S1D67', 'S2D34', 'S2D36', 'S2D140', 'S2D142', 'S3D39', 'S3D40', 'S3D65', 'S3D68', 'S3D69', 'S3D70', 'S4D33', 'S4D34', 'S4D37', 'S4D38', 'S4D39', 'S4D144', 'S5D137', 'S5D138', 'S5D139', 'S5D142', 'S5D143', 'S5D144', 'S6D1', 'S6D17', 'S6D66', 'S6D68', 'S6D71', 'S7D35', 'S7D37', 'S7D40', 'S7D66', 'S7D130', 'S8D33', 'S8D35', 'S8D134', 'S8D141', 'S8D143', 'S9D94', 'S9D96', 'S9D135', 'S9D139', 'S9D141', 'S10D87', 'S10D89', 'S10D92', 'S10D94', 'S10D136', 'S11D82', 'S11D85', 'S11D87', 'S11D104', 'S11D112', 'S12D90', 'S12D91', 'S12D92', 'S12D95', 'S12D96', 'S12D137', 'S13D83', 'S13D84', 'S13D85', 'S13D88', 'S13D89', 'S13D90', 'S14D93', 'S14D95', 'S14D138', 'S14D140', 'S15D86', 'S15D88', 'S15D91', 'S15D93', 'S16D81', 'S16D84', 'S16D86', 'S16D103', 'S17D97', 'S17D99', 'S17D102', 'S17D104', 'S17D111', 'S18D74', 'S18D115', 'S18D117', 'S18D120', 'S18D127', 'S19D74', 'S19D76', 'S19D79', 'S19D97', 'S19D128', 'S20D81', 'S20D82', 'S20D83', 'S20D100', 'S20D101', 'S20D102', 'S21D75', 'S21D76', 'S21D77', 'S21D118', 'S21D119', 'S21D120', 'S22D77', 'S22D78', 'S22D79', 'S22D98', 'S22D99', 'S22D100', 'S23D80', 'S23D98', 'S23D101', 'S23D103', 'S24D73', 'S24D75', 'S24D78', 'S24D80', 'S25D8', 'S25D10', 'S25D13', 'S25D15', 'S25D19', 'S26D1', 'S26D3', 'S26D6', 'S26D8', 'S26D18', 'S27D5', 'S27D6', 'S27D7', 'S27D10', 'S27D11', 'S27D12', 'S28D12', 'S28D13', 'S28D14', 'S28D41', 'S28D42', 'S28D43', 'S29D3', 'S29D4', 'S29D5', 'S29D70', 'S29D71', 'S29D72', 'S30D9', 'S30D11', 'S30D14', 'S30D16', 'S31D2', 'S31D4', 'S31D7', 'S31D9', 'S32D2', 'S32D67', 'S32D69', 'S32D72', 'S33D51', 'S33D52', 'S33D62', 'S33D64', 'S34D47', 'S34D57', 'S34D60', 'S34D62', 'S35D16', 'S35D42', 'S35D45', 'S35D47', 'S36D49', 'S36D58', 'S36D59', 'S36D60', 'S36D63', 'S36D64', 'S37D43', 'S37D44', 'S37D45', 'S37D48', 'S37D57', 'S37D58', 'S38D25', 'S38D50', 'S38D61', 'S38D63', 'S38D121', 'S39D27', 'S39D46', 'S39D48', 'S39D59', 'S39D61', 'S40D15', 'S40D28', 'S40D41', 'S40D44', 'S40D46', 'S41D73', 'S41D114', 'S41D116', 'S41D119', 'S42D52', 'S42D54', 'S42D55', 'S42D114', 'S43D49', 'S43D50', 'S43D51', 'S43D53', 'S43D54', 'S43D56', 'S44D55', 'S44D56', 'S44D113', 'S44D116', 'S44D117', 'S44D118', 'S45D25', 'S45D53', 'S45D113', 'S45D115', 'S45D126', 'S46D108', 'S46D109', 'S46D110', 'S46D111', 'S46D125', 'S46D128', 'S47D123', 'S47D124', 'S47D126', 'S48D106', 'S48D109', 'S48D122', 'S48D124', 'S49D29', 'S49D32', 'S49D122', 'S49D123', 'S50D26', 'S50D27', 'S50D28', 'S50D29', 'S50D30', 'S50D31', 'S51D105', 'S51D131', 'S51D132', 'S52D107', 'S52D110', 'S52D112', 'S52D132', 'S52D133', 'S52D136', 'S53D18', 'S53D19', 'S53D20', 'S53D22', 'S53D23', 'S53D31', 'S54D129', 'S54D131', 'S54D133', 'S54D134', 'S54D135', 'S55D21', 'S55D22', 'S55D24', 'S56D17', 'S56D20', 'S56D21', 'S56D129', 'S56D130']}, 'subset_1': {'n_optodes': 156, 'n_optodes_percent': 78.0, 'all': ['S1D36', 'S1D38', 'S1D39', 'S1D67', 'S1D69', 'S2D36', 'S2D38', 'S2D140', 'S2D142', 'S2D144', 'S3D37', 'S3D38', 'S3D39', 'S3D66', 'S3D67', 'S3D68', 'S3D69', 'S3D70', 'S4D35', 'S4D36', 'S4D37', 'S4D38', 'S4D39', 'S4D142', 'S4D143', 'S4D144', 'S5D95', 'S5D96', 'S5D137', 'S5D140', 'S5D141', 'S5D142', 'S5D143', 'S5D144', 'S6D1', 'S6D3', 'S6D18', 'S6D20', 'S6D66', 'S6D68', 'S6D70', 'S6D130', 'S7D35', 'S7D37', 'S7D39', 'S7D66', 'S7D68', 'S7D130', 'S7D134', 'S8D35', 'S8D37', 'S8D130', 'S8D134', 'S8D141', 'S8D143', 'S8D144', 'S9D94', 'S9D96', 'S9D133', 'S9D134', 'S9D136', 'S9D137', 'S9D141', 'S9D143', 'S10D87', 'S10D89', 'S10D90', 'S10D94', 'S10D96', 'S10D133', 'S10D136', 'S11D82', 'S11D83', 'S11D87', 'S11D89', 'S11D104', 'S11D111', 'S11D136', 'S12D88', 'S12D89', 'S12D90', 'S12D93', 'S12D94', 'S12D95', 'S12D96', 'S12D137', 'S13D81', 'S13D82', 'S13D83', 'S13D86', 'S13D87', 'S13D88', 'S13D89', 'S13D90', 'S14D93', 'S14D95', 'S14D137', 'S14D140', 'S14D142', 'S15D86', 'S15D88', 'S15D90', 'S15D93', 'S15D95', 'S16D81', 'S16D83', 'S16D86', 'S16D88', 'S16D103', 'S17D82', 'S17D97', 'S17D99', 'S17D100', 'S17D104', 'S17D111', 'S18D74', 'S18D76', 'S18D115', 'S18D117', 'S18D118', 'S18D125', 'S18D127', 'S19D74', 'S19D76', 'S19D77', 'S19D97', 'S19D99', 'S19D111', 'S19D125', 'S19D127', 'S20D81', 'S20D82', 'S20D83', 'S20D98', 'S20D99', 'S20D100', 'S20D103', 'S20D104', 'S21D73', 'S21D74', 'S21D75', 'S21D76', 'S21D77', 'S21D116', 'S21D117', 'S21D118', 'S22D75', 'S22D76', 'S22D77', 'S22D80', 'S22D97', 'S22D98', 'S22D99', 'S22D100', 'S23D80', 'S23D81', 'S23D98', 'S23D100', 'S23D103', 'S24D73', 'S24D75', 'S24D77', 'S24D80', 'S24D98', 'S25D8', 'S25D10', 'S25D12', 'S25D15', 'S25D18', 'S25D28', 'S25D41', 'S26D1', 'S26D3', 'S26D5', 'S26D8', 'S26D10', 'S26D18', 'S26D20', 'S27D3', 'S27D4', 'S27D5', 'S27D8', 'S27D9', 'S27D10', 'S27D11', 'S27D12', 'S28D10', 'S28D11', 'S28D12', 'S28D15', 'S28D16', 'S28D41', 'S28D42', 'S28D43', 'S29D1', 'S29D2', 'S29D3', 'S29D4', 'S29D5', 'S29D68', 'S29D69', 'S29D70', 'S30D9', 'S30D11', 'S30D12', 'S30D16', 'S30D42', 'S31D2', 'S31D4', 'S31D5', 'S31D9', 'S31D11', 'S32D2', 'S32D4', 'S32D67', 'S32D69', 'S32D70', 'S33D49', 'S33D52', 'S33D54', 'S33D62', 'S33D64', 'S34D47', 'S34D57', 'S34D58', 'S34D62', 'S34D64', 'S35D16', 'S35D42', 'S35D43', 'S35D47', 'S35D57', 'S36D48', 'S36D49', 'S36D57', 'S36D58', 'S36D61', 'S36D62', 'S36D63', 'S36D64', 'S37D41', 'S37D42', 'S37D43', 'S37D46', 'S37D47', 'S37D48', 'S37D57', 'S37D58', 'S38D25', 'S38D26', 'S38D49', 'S38D53', 'S38D61', 'S38D63', 'S38D121', 'S39D26', 'S39D28', 'S39D46', 'S39D48', 'S39D58', 'S39D61', 'S39D63', 'S39D121', 'S40D15', 'S40D28', 'S40D41', 'S40D43', 'S40D46', 'S40D48', 'S41D73', 'S41D75', 'S41D114', 'S41D116', 'S41D118', 'S42D52', 'S42D54', 'S42D56', 'S42D114', 'S42D116', 'S43D25', 'S43D49', 'S43D52', 'S43D53', 'S43D54', 'S43D56', 'S43D63', 'S43D64', 'S44D53', 'S44D54', 'S44D56', 'S44D114', 'S44D115', 'S44D116', 'S44D117', 'S44D118', 'S45D25', 'S45D53', 'S45D56', 'S45D115', 'S45D117', 'S45D121', 'S45D127', 'S46D97', 'S46D104', 'S46D107', 'S46D108', 'S46D109', 'S46D111', 'S46D124', 'S46D125', 'S46D127', 'S47D25', 'S47D26', 'S47D29', 'S47D109', 'S47D115', 'S47D121', 'S47D123', 'S47D124', 'S47D125', 'S47D127', 'S48D107', 'S48D108', 'S48D109', 'S48D122', 'S48D123', 'S48D124', 'S48D125', 'S49D23', 'S49D26', 'S49D29', 'S49D30', 'S49D122', 'S49D123', 'S49D124', 'S50D23', 'S50D26', 'S50D28', 'S50D29', 'S50D30', 'S50D46', 'S50D61', 'S50D121', 'S50D123', 'S51D21', 'S51D107', 'S51D108', 'S51D122', 'S51D131', 'S51D132', 'S51D133', 'S52D87', 'S52D94', 'S52D107', 'S52D108', 'S52D111', 'S52D131', 'S52D132', 'S52D133', 'S52D136', 'S53D8', 'S53D15', 'S53D18', 'S53D20', 'S53D21', 'S53D22', 'S53D23', 'S53D28', 'S53D30', 'S54D35', 'S54D130', 'S54D131', 'S54D132', 'S54D133', 'S54D134', 'S54D136', 'S54D141', 'S55D20', 'S55D21', 'S55D22', 'S55D23', 'S55D122', 'S55D131', 'S56D1', 'S56D18', 'S56D20', 'S56D21', 'S56D22', 'S56D66', 'S56D130', 'S56D134'], 'all_percent': 67.88, 'long': ['S1D39', 'S1D69', 'S2D38', 'S2D144', 'S3D37', 'S3D38', 'S3D66', 'S3D67', 'S4D35', 'S4D36', 'S4D142', 'S4D143', 'S5D95', 'S5D96', 'S5D140', 'S5D141', 'S6D3', 'S6D18', 'S6D20', 'S6D70', 'S6D130', 'S7D39', 'S7D68', 'S7D134', 'S8D37', 'S8D130', 'S8D144', 'S9D133', 'S9D134', 'S9D136', 'S9D137', 'S9D143', 'S10D90', 'S10D96', 'S10D133', 'S11D83', 'S11D89', 'S11D111', 'S11D136', 'S12D88', 'S12D89', 'S12D93', 'S12D94', 'S13D81', 'S13D82', 'S13D86', 'S13D87', 'S14D137', 'S14D142', 'S15D90', 'S15D95', 'S16D83', 'S16D88', 'S17D82', 'S17D100', 'S18D76', 'S18D118', 'S18D125', 'S19D77', 'S19D99', 'S19D111', 'S19D125', 'S19D127', 'S20D98', 'S20D99', 'S20D103', 'S20D104', 'S21D73', 'S21D74', 'S21D116', 'S21D117', 'S22D75', 'S22D76', 'S22D80', 'S22D97', 'S23D81', 'S23D100', 'S24D77', 'S24D98', 'S25D12', 'S25D18', 'S25D28', 'S25D41', 'S26D5', 'S26D10', 'S26D20', 'S27D3', 'S27D4', 'S27D8', 'S27D9', 'S28D10', 'S28D11', 'S28D15', 'S28D16', 'S29D1', 'S29D2', 'S29D68', 'S29D69', 'S30D12', 'S30D42', 'S31D5', 'S31D11', 'S32D4', 'S32D70', 'S33D49', 'S33D54', 'S34D58', 'S34D64', 'S35D43', 'S35D57', 'S36D48', 'S36D57', 'S36D61', 'S36D62', 'S37D41', 'S37D42', 'S37D46', 'S37D47', 'S38D26', 'S38D49', 'S38D53', 'S39D26', 'S39D28', 'S39D58', 'S39D63', 'S39D121', 'S40D43', 'S40D48', 'S41D75', 'S41D118', 'S42D56', 'S42D116', 'S43D25', 'S43D52', 'S43D63', 'S43D64', 'S44D53', 'S44D54', 'S44D114', 'S44D115', 'S45D56', 'S45D117', 'S45D121', 'S45D127', 'S46D97', 'S46D104', 'S46D107', 'S46D124', 'S46D127', 'S47D25', 'S47D26', 'S47D29', 'S47D109', 'S47D115', 'S47D121', 'S47D125', 'S47D127', 'S48D107', 'S48D108', 'S48D123', 'S48D125', 'S49D23', 'S49D26', 'S49D30', 'S49D124', 'S50D23', 'S50D46', 'S50D61', 'S50D121', 'S50D123', 'S51D21', 'S51D107', 'S51D108', 'S51D122', 'S51D133', 'S52D87', 'S52D94', 'S52D108', 'S52D111', 'S52D131', 'S53D8', 'S53D15', 'S53D21', 'S53D28', 'S53D30', 'S54D35', 'S54D130', 'S54D132', 'S54D136', 'S54D141', 'S55D20', 'S55D23', 'S55D122', 'S55D131', 'S56D1', 'S56D18', 'S56D22', 'S56D66', 'S56D134'], 'long_percent': 66.33, 'short': ['S1D36', 'S1D38', 'S1D67', 'S2D36', 'S2D140', 'S2D142', 'S3D39', 'S3D68', 'S3D69', 'S3D70', 'S4D37', 'S4D38', 'S4D39', 'S4D144', 'S5D137', 'S5D142', 'S5D143', 'S5D144', 'S6D1', 'S6D66', 'S6D68', 'S7D35', 'S7D37', 'S7D66', 'S7D130', 'S8D35', 'S8D134', 'S8D141', 'S8D143', 'S9D94', 'S9D96', 'S9D141', 'S10D87', 'S10D89', 'S10D94', 'S10D136', 'S11D82', 'S11D87', 'S11D104', 'S12D90', 'S12D95', 'S12D96', 'S12D137', 'S13D83', 'S13D88', 'S13D89', 'S13D90', 'S14D93', 'S14D95', 'S14D140', 'S15D86', 'S15D88', 'S15D93', 'S16D81', 'S16D86', 'S16D103', 'S17D97', 'S17D99', 'S17D104', 'S17D111', 'S18D74', 'S18D115', 'S18D117', 'S18D127', 'S19D74', 'S19D76', 'S19D97', 'S20D81', 'S20D82', 'S20D83', 'S20D100', 'S21D75', 'S21D76', 'S21D77', 'S21D118', 'S22D77', 'S22D98', 'S22D99', 'S22D100', 'S23D80', 'S23D98', 'S23D103', 'S24D73', 'S24D75', 'S24D80', 'S25D8', 'S25D10', 'S25D15', 'S26D1', 'S26D3', 'S26D8', 'S26D18', 'S27D5', 'S27D10', 'S27D11', 'S27D12', 'S28D12', 'S28D41', 'S28D42', 'S28D43', 'S29D3', 'S29D4', 'S29D5', 'S29D70', 'S30D9', 'S30D11', 'S30D16', 'S31D2', 'S31D4', 'S31D9', 'S32D2', 'S32D67', 'S32D69', 'S33D52', 'S33D62', 'S33D64', 'S34D47', 'S34D57', 'S34D62', 'S35D16', 'S35D42', 'S35D47', 'S36D49', 'S36D58', 'S36D63', 'S36D64', 'S37D43', 'S37D48', 'S37D57', 'S37D58', 'S38D25', 'S38D61', 'S38D63', 'S38D121', 'S39D46', 'S39D48', 'S39D61', 'S40D15', 'S40D28', 'S40D41', 'S40D46', 'S41D73', 'S41D114', 'S41D116', 'S42D52', 'S42D54', 'S42D114', 'S43D49', 'S43D53', 'S43D54', 'S43D56', 'S44D56', 'S44D116', 'S44D117', 'S44D118', 'S45D25', 'S45D53', 'S45D115', 'S46D108', 'S46D109', 'S46D111', 'S46D125', 'S47D123', 'S47D124', 'S48D109', 'S48D122', 'S48D124', 'S49D29', 'S49D122', 'S49D123', 'S50D26', 'S50D28', 'S50D29', 'S50D30', 'S51D131', 'S51D132', 'S52D107', 'S52D132', 'S52D133', 'S52D136', 'S53D18', 'S53D20', 'S53D22', 'S53D23', 'S54D131', 'S54D133', 'S54D134', 'S55D21', 'S55D22', 'S56D20', 'S56D21', 'S56D130']}, 'subset_2': {'n_optodes': 116, 'n_optodes_percent': 58.0, 'all': ['S1D36', 'S1D39', 'S1D67', 'S2D36', 'S2D140', 'S2D144', 'S3D39', 'S3D66', 'S3D67', 'S3D70', 'S4D35', 'S4D36', 'S4D39', 'S4D144', 'S5D137', 'S5D140', 'S5D141', 'S5D144', 'S6D1', 'S6D18', 'S6D66', 'S6D70', 'S6D130', 'S7D35', 'S7D39', 'S7D66', 'S7D130', 'S7D134', 'S8D35', 'S8D130', 'S8D134', 'S8D141', 'S8D144', 'S9D94', 'S9D134', 'S9D136', 'S9D137', 'S9D141', 'S10D87', 'S10D90', 'S10D94', 'S10D136', 'S11D83', 'S11D87', 'S11D104', 'S11D111', 'S11D136', 'S12D90', 'S12D93', 'S12D94', 'S12D137', 'S13D83', 'S13D86', 'S13D87', 'S13D90', 'S14D93', 'S14D137', 'S14D140', 'S15D86', 'S15D90', 'S15D93', 'S16D83', 'S16D86', 'S16D103', 'S17D97', 'S17D100', 'S17D104', 'S17D111', 'S18D74', 'S18D115', 'S18D118', 'S18D127', 'S19D74', 'S19D77', 'S19D97', 'S19D111', 'S19D127', 'S20D83', 'S20D100', 'S20D103', 'S20D104', 'S21D73', 'S21D74', 'S21D77', 'S21D118', 'S22D77', 'S22D80', 'S22D97', 'S22D100', 'S23D80', 'S23D100', 'S23D103', 'S24D73', 'S24D77', 'S24D80', 'S25D8', 'S25D12', 'S25D15', 'S25D18', 'S25D28', 'S26D1', 'S26D5', 'S26D8', 'S26D18', 'S27D5', 'S27D8', 'S27D9', 'S27D12', 'S28D12', 'S28D15', 'S28D16', 'S28D43', 'S29D1', 'S29D2', 'S29D5', 'S29D70', 'S30D9', 'S30D12', 'S30D16', 'S31D2', 'S31D5', 'S31D9', 'S32D2', 'S32D67', 'S32D70', 'S33D49', 'S33D52', 'S33D62', 'S34D47', 'S34D58', 'S34D62', 'S35D16', 'S35D43', 'S35D47', 'S36D49', 'S36D58', 'S36D61', 'S36D62', 'S37D43', 'S37D46', 'S37D47', 'S37D58', 'S38D25', 'S38D49', 'S38D61', 'S38D121', 'S39D28', 'S39D46', 'S39D58', 'S39D61', 'S39D121', 'S40D15', 'S40D28', 'S40D43', 'S40D46', 'S41D73', 'S41D114', 'S41D118', 'S42D52', 'S42D56', 'S42D114', 'S43D25', 'S43D49', 'S43D52', 'S43D56', 'S44D56', 'S44D114', 'S44D115', 'S44D118', 'S45D25', 'S45D56', 'S45D115', 'S45D121', 'S45D127', 'S46D97', 'S46D104', 'S46D108', 'S46D111', 'S46D124', 'S46D127', 'S47D25', 'S47D115', 'S47D121', 'S47D123', 'S47D124', 'S47D127', 'S48D108', 'S48D122', 'S48D123', 'S48D124', 'S49D30', 'S49D122', 'S49D123', 'S49D124', 'S50D28', 'S50D30', 'S50D46', 'S50D61', 'S50D121', 'S50D123', 'S51D108', 'S51D122', 'S51D132', 'S52D87', 'S52D94', 'S52D108', 'S52D111', 'S52D132', 'S52D136', 'S53D8', 'S53D15', 'S53D18', 'S53D22', 'S53D28', 'S53D30', 'S54D35', 'S54D130', 'S54D132', 'S54D134', 'S54D136', 'S54D141', 'S55D22', 'S55D122', 'S56D1', 'S56D18', 'S56D22', 'S56D66', 'S56D130', 'S56D134'], 'all_percent': 39.76, 'long': ['S1D39', 'S2D144', 'S3D66', 'S3D67', 'S4D35', 'S4D36', 'S5D140', 'S5D141', 'S6D18', 'S6D70', 'S6D130', 'S7D39', 'S7D134', 'S8D130', 'S8D144', 'S9D134', 'S9D136', 'S9D137', 'S10D90', 'S11D83', 'S11D111', 'S11D136', 'S12D93', 'S12D94', 'S13D86', 'S13D87', 'S14D137', 'S15D90', 'S16D83', 'S17D100', 'S18D118', 'S19D77', 'S19D111', 'S19D127', 'S20D103', 'S20D104', 'S21D73', 'S21D74', 'S22D80', 'S22D97', 'S23D100', 'S24D77', 'S25D12', 'S25D18', 'S25D28', 'S26D5', 'S27D8', 'S27D9', 'S28D15', 'S28D16', 'S29D1', 'S29D2', 'S30D12', 'S31D5', 'S32D70', 'S33D49', 'S34D58', 'S35D43', 'S36D61', 'S36D62', 'S37D46', 'S37D47', 'S38D49', 'S39D28', 'S39D58', 'S39D121', 'S40D43', 'S41D118', 'S42D56', 'S43D25', 'S43D52', 'S44D114', 'S44D115', 'S45D56', 'S45D121', 'S45D127', 'S46D97', 'S46D104', 'S46D124', 'S46D127', 'S47D25', 'S47D115', 'S47D121', 'S47D127', 'S48D108', 'S48D123', 'S49D30', 'S49D124', 'S50D46', 'S50D61', 'S50D121', 'S50D123', 'S51D108', 'S51D122', 'S52D87', 'S52D94', 'S52D108', 'S52D111', 'S53D8', 'S53D15', 'S53D28', 'S53D30', 'S54D35', 'S54D130', 'S54D132', 'S54D136', 'S54D141', 'S55D122', 'S56D1', 'S56D18', 'S56D22', 'S56D66', 'S56D134'], 'long_percent': 37.67, 'short': ['S1D36', 'S1D67', 'S2D36', 'S2D140', 'S3D39', 'S3D70', 'S4D39', 'S4D144', 'S5D137', 'S5D144', 'S6D1', 'S6D66', 'S7D35', 'S7D66', 'S7D130', 'S8D35', 'S8D134', 'S8D141', 'S9D94', 'S9D141', 'S10D87', 'S10D94', 'S10D136', 'S11D87', 'S11D104', 'S12D90', 'S12D137', 'S13D83', 'S13D90', 'S14D93', 'S14D140', 'S15D86', 'S15D93', 'S16D86', 'S16D103', 'S17D97', 'S17D104', 'S17D111', 'S18D74', 'S18D115', 'S18D127', 'S19D74', 'S19D97', 'S20D83', 'S20D100', 'S21D77', 'S21D118', 'S22D77', 'S22D100', 'S23D80', 'S23D103', 'S24D73', 'S24D80', 'S25D8', 'S25D15', 'S26D1', 'S26D8', 'S26D18', 'S27D5', 'S27D12', 'S28D12', 'S28D43', 'S29D5', 'S29D70', 'S30D9', 'S30D16', 'S31D2', 'S31D9', 'S32D2', 'S32D67', 'S33D52', 'S33D62', 'S34D47', 'S34D62', 'S35D16', 'S35D47', 'S36D49', 'S36D58', 'S37D43', 'S37D58', 'S38D25', 'S38D61', 'S38D121', 'S39D46', 'S39D61', 'S40D15', 'S40D28', 'S40D46', 'S41D73', 'S41D114', 'S42D52', 'S42D114', 'S43D49', 'S43D56', 'S44D56', 'S44D118', 'S45D25', 'S45D115', 'S46D108', 'S46D111', 'S47D123', 'S47D124', 'S48D122', 'S48D124', 'S49D122', 'S49D123', 'S50D28', 'S50D30', 'S51D132', 'S52D132', 'S52D136', 'S53D18', 'S53D22', 'S54D134', 'S55D22', 'S56D130']}, 'subset_3': {'n_optodes': 61, 'n_optodes_percent': 30.5, 'all': ['S3D66', 'S3D67', 'S4D35', 'S4D36', 'S5D140', 'S5D141', 'S12D93', 'S12D94', 'S13D86', 'S13D87', 'S20D103', 'S20D104', 'S21D73', 'S21D74', 'S22D80', 'S22D97', 'S27D8', 'S27D9', 'S28D15', 'S28D16', 'S29D1', 'S29D2', 'S36D61', 'S36D62', 'S37D46', 'S37D47', 'S43D25', 'S43D52', 'S44D114', 'S44D115', 'S46D97', 'S46D104', 'S46D108', 'S47D25', 'S47D115', 'S48D108', 'S48D122', 'S49D30', 'S49D122', 'S50D30', 'S50D46', 'S50D61', 'S51D108', 'S51D122', 'S51D132', 'S52D87', 'S52D94', 'S52D108', 'S52D132', 'S53D8', 'S53D15', 'S53D22', 'S53D30', 'S54D35', 'S54D132', 'S54D141', 'S55D22', 'S55D122', 'S56D1', 'S56D22', 'S56D66'], 'all_percent': 10.59, 'long': ['S3D66', 'S3D67', 'S4D35', 'S4D36', 'S5D140', 'S5D141', 'S12D93', 'S12D94', 'S13D86', 'S13D87', 'S20D103', 'S20D104', 'S21D73', 'S21D74', 'S22D80', 'S22D97', 'S27D8', 'S27D9', 'S28D15', 'S28D16', 'S29D1', 'S29D2', 'S36D61', 'S36D62', 'S37D46', 'S37D47', 'S43D25', 'S43D52', 'S44D114', 'S44D115', 'S46D97', 'S46D104', 'S47D25', 'S47D115', 'S48D108', 'S49D30', 'S50D46', 'S50D61', 'S51D108', 'S51D122', 'S52D87', 'S52D94', 'S52D108', 'S53D8', 'S53D15', 'S53D30', 'S54D35', 'S54D132', 'S54D141', 'S55D122', 'S56D1', 'S56D22', 'S56D66'], 'long_percent': 17.67, 'short': ['S46D108', 'S48D122', 'S49D122', 'S50D30', 'S51D132', 'S52D132', 'S53D22', 'S55D22']}}\n",
      "/home/thomas/Dokumente/Master/Master_Thesis/HD-DOT Classification/data/BS_Laura/epochs_labels/test/sub-577/run0_epochs_labels.pkl\n",
      "/home/thomas/Dokumente/Master/Master_Thesis/HD-DOT Classification/data/BS_Laura/epochs_labels/test/sub-577/run1_epochs_labels.pkl\n",
      "/home/thomas/Dokumente/Master/Master_Thesis/HD-DOT Classification/data/BS_Laura/epochs_labels/test/sub-577/run2_epochs_labels.pkl\n",
      "/home/thomas/Dokumente/Master/Master_Thesis/HD-DOT Classification/data/BS_Laura/epochs_labels/test/sub-580/run0_epochs_labels.pkl\n",
      "/home/thomas/Dokumente/Master/Master_Thesis/HD-DOT Classification/data/BS_Laura/epochs_labels/test/sub-580/run1_epochs_labels.pkl\n",
      "/home/thomas/Dokumente/Master/Master_Thesis/HD-DOT Classification/data/BS_Laura/epochs_labels/test/sub-580/run2_epochs_labels.pkl\n",
      "/home/thomas/Dokumente/Master/Master_Thesis/HD-DOT Classification/data/BS_Laura/epochs_labels/test/sub-586/run0_epochs_labels.pkl\n",
      "/home/thomas/Dokumente/Master/Master_Thesis/HD-DOT Classification/data/BS_Laura/epochs_labels/test/sub-586/run1_epochs_labels.pkl\n",
      "/home/thomas/Dokumente/Master/Master_Thesis/HD-DOT Classification/data/BS_Laura/epochs_labels/test/sub-586/run2_epochs_labels.pkl\n",
      "/home/thomas/Dokumente/Master/Master_Thesis/HD-DOT Classification/data/BS_Laura/epochs_labels/test/sub-587/run0_epochs_labels.pkl\n",
      "/home/thomas/Dokumente/Master/Master_Thesis/HD-DOT Classification/data/BS_Laura/epochs_labels/test/sub-587/run1_epochs_labels.pkl\n",
      "/home/thomas/Dokumente/Master/Master_Thesis/HD-DOT Classification/data/BS_Laura/epochs_labels/test/sub-587/run2_epochs_labels.pkl\n",
      "/home/thomas/Dokumente/Master/Master_Thesis/HD-DOT Classification/data/BS_Laura/epochs_labels/test/sub-592/run0_epochs_labels.pkl\n",
      "/home/thomas/Dokumente/Master/Master_Thesis/HD-DOT Classification/data/BS_Laura/epochs_labels/test/sub-592/run1_epochs_labels.pkl\n",
      "/home/thomas/Dokumente/Master/Master_Thesis/HD-DOT Classification/data/BS_Laura/epochs_labels/test/sub-592/run2_epochs_labels.pkl\n",
      "/home/thomas/Dokumente/Master/Master_Thesis/HD-DOT Classification/data/BS_Laura/epochs_labels/test/sub-613/run0_epochs_labels.pkl\n",
      "/home/thomas/Dokumente/Master/Master_Thesis/HD-DOT Classification/data/BS_Laura/epochs_labels/test/sub-613/run1_epochs_labels.pkl\n",
      "/home/thomas/Dokumente/Master/Master_Thesis/HD-DOT Classification/data/BS_Laura/epochs_labels/test/sub-613/run2_epochs_labels.pkl\n",
      "/home/thomas/Dokumente/Master/Master_Thesis/HD-DOT Classification/data/BS_Laura/epochs_labels/test/sub-618/run0_epochs_labels.pkl\n",
      "/home/thomas/Dokumente/Master/Master_Thesis/HD-DOT Classification/data/BS_Laura/epochs_labels/test/sub-618/run1_epochs_labels.pkl\n",
      "/home/thomas/Dokumente/Master/Master_Thesis/HD-DOT Classification/data/BS_Laura/epochs_labels/test/sub-618/run2_epochs_labels.pkl\n",
      "/home/thomas/Dokumente/Master/Master_Thesis/HD-DOT Classification/data/BS_Laura/epochs_labels/test/sub-619/run0_epochs_labels.pkl\n",
      "/home/thomas/Dokumente/Master/Master_Thesis/HD-DOT Classification/data/BS_Laura/epochs_labels/test/sub-619/run1_epochs_labels.pkl\n",
      "/home/thomas/Dokumente/Master/Master_Thesis/HD-DOT Classification/data/BS_Laura/epochs_labels/test/sub-619/run2_epochs_labels.pkl\n",
      "/home/thomas/Dokumente/Master/Master_Thesis/HD-DOT Classification/data/BS_Laura/epochs_labels/test/sub-621/run0_epochs_labels.pkl\n",
      "/home/thomas/Dokumente/Master/Master_Thesis/HD-DOT Classification/data/BS_Laura/epochs_labels/test/sub-621/run1_epochs_labels.pkl\n",
      "/home/thomas/Dokumente/Master/Master_Thesis/HD-DOT Classification/data/BS_Laura/epochs_labels/test/sub-621/run2_epochs_labels.pkl\n",
      "/home/thomas/Dokumente/Master/Master_Thesis/HD-DOT Classification/data/BS_Laura/epochs_labels/test/sub-633/run0_epochs_labels.pkl\n",
      "/home/thomas/Dokumente/Master/Master_Thesis/HD-DOT Classification/data/BS_Laura/epochs_labels/test/sub-633/run1_epochs_labels.pkl\n",
      "/home/thomas/Dokumente/Master/Master_Thesis/HD-DOT Classification/data/BS_Laura/epochs_labels/test/sub-633/run2_epochs_labels.pkl\n",
      "/home/thomas/Dokumente/Master/Master_Thesis/HD-DOT Classification/data/BS_Laura/epochs_labels/test/sub-638/run0_epochs_labels.pkl\n",
      "/home/thomas/Dokumente/Master/Master_Thesis/HD-DOT Classification/data/BS_Laura/epochs_labels/test/sub-638/run1_epochs_labels.pkl\n",
      "/home/thomas/Dokumente/Master/Master_Thesis/HD-DOT Classification/data/BS_Laura/epochs_labels/test/sub-638/run2_epochs_labels.pkl\n",
      "/home/thomas/Dokumente/Master/Master_Thesis/HD-DOT Classification/data/BS_Laura/epochs_labels/test/sub-640/run0_epochs_labels.pkl\n",
      "/home/thomas/Dokumente/Master/Master_Thesis/HD-DOT Classification/data/BS_Laura/epochs_labels/test/sub-640/run1_epochs_labels.pkl\n",
      "/home/thomas/Dokumente/Master/Master_Thesis/HD-DOT Classification/data/BS_Laura/epochs_labels/test/sub-640/run2_epochs_labels.pkl\n",
      "\n",
      "Feature type: Slope \n",
      "\n",
      "\n",
      "Pruning channels: True \n",
      "\n",
      "\n",
      "Feature reduction: False \n",
      "\n",
      "biggest subset size:  576\n",
      "parcel subset size:  104\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "classifiers = {\n",
    "    'LDA': LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto'),\n",
    "    #'SVC_lin': SVC(kernel='linear', probability=True, C=0.1),\n",
    "}\n",
    "\n",
    "save_plot = True\n",
    "\n",
    "prune_by_zeroing = True\n",
    "n_reduced_feat_ws = 30\n",
    "n_reduced_feat_loso = 30\n",
    "spatial_scaling = 2\n",
    "datasets_path = \"/home/thomas/Dokumente/Master/Master_Thesis/datasets/\"\n",
    "\n",
    "dt_conditions_parcel = [\n",
    "    \"all_od\", \n",
    "    \"all_od_ss_mean_full\"\n",
    "]\n",
    "\n",
    "dt_labels_parcel = {\n",
    "    \"all_od\": \"Parcel No SS Correction\",\n",
    "    \"all_od_ss_mean_full\": \"Parcel SS corrected\",\n",
    "}\n",
    "\n",
    "all_parcel_features = {dtcp: {} for dtcp in dt_conditions_parcel}\n",
    "parcel_features_by_dt = {dt: {dtcp: {} for dtcp in dt_conditions_parcel} for dt in data_types}\n",
    "\n",
    "# Main pipeline\n",
    "for data_type in data_types:\n",
    "\n",
    "    print(f\"\\nProcessing {data_type} dataset... \\n\")\n",
    "\n",
    "    cfg = dataset_configs[data_type]\n",
    "    synthetic = cfg.synthetic\n",
    "    subjects = cfg.subjects\n",
    "    #subjects = subjects[0:2]  # For testing, only use the first subject\n",
    "    base_path = cfg.base_path\n",
    "    ft_slices = cfg.feature_slices\n",
    "    long_chs = cfg.long_channels\n",
    "    probe_area = cfg.probe_area\n",
    "    with open(os.path.join(base_path, 'subsets_data'), 'rb') as file:\n",
    "        subsets_data = pickle.load(file)\n",
    "    subset_keys = list(reversed(subsets_data.keys()))\n",
    "\n",
    "    print(\"SUBSETS\")\n",
    "    print(subsets_data)\n",
    "\n",
    "    clean_ch_map = {}\n",
    "    for subject_idx, subject in enumerate(subjects):\n",
    "        clean_ch_map[subject] = {}\n",
    "        for run in range(cfg.n_runs(subject_idx)):\n",
    "            clean_ch_map[subject][run] = {}\n",
    "            with open(os.path.join(base_path, cfg.clean_channels_path(subject, run)), 'rb') as f:\n",
    "                clean_ch_map[subject][run]['parcel'] = pickle.load(f)\n",
    "\n",
    "    result_path = f'/home/thomas/Dokumente/Master/Master_Thesis/results/{data_type}/channel_space/'\n",
    "\n",
    "    for int_scaling in ['03']:\n",
    "        data = {}\n",
    "        for subject_idx, subject in enumerate(subjects):\n",
    "            data[subject] = {}\n",
    "            n_runs = cfg.n_runs(subject_idx)\n",
    "            for run in range(n_runs):\n",
    "                ep_path = cfg.epochs_labels_path(subject, run, int_scaling, spatial_scaling)\n",
    "                print(os.path.join(base_path, ep_path))\n",
    "                with open(os.path.join(base_path, ep_path), 'rb') as f:\n",
    "                    data[subject][run] = pickle.load(f)\n",
    "\n",
    "        for feature_types in ['Slope']:\n",
    "\n",
    "            print(f\"\\nFeature type: {feature_types} \\n\")\n",
    "\n",
    "            for prune_channels in [True]:\n",
    "\n",
    "                print(f\"\\nPruning channels: {prune_channels} \\n\")\n",
    "\n",
    "                for reduce_features in [False]:\n",
    "\n",
    "                    print(f\"\\nFeature reduction: {reduce_features} \\n\")\n",
    "\n",
    "                    ############### ---- PARCEL SPACE CLASSIFICATION (per subject) ############### \n",
    "\n",
    "                    full_channel_subset = subsets_data['full']['all']\n",
    "\n",
    "                    selected_Adot = cfg.Adot\n",
    "                    selected_B = cfg.B\n",
    "\n",
    "                    if synthetic:\n",
    "                        selected_channels_mask = np.isin(selected_Adot.channel.values, full_channel_subset)\n",
    "                        selected_Adot = selected_Adot[selected_channels_mask,:]\n",
    "                        selected_channels_mask_stacked = np.tile(selected_channels_mask, 2)\n",
    "                        selected_B = selected_B[:, selected_channels_mask_stacked]\n",
    "\n",
    "\n",
    "                    print(\"biggest subset size: \", len(full_channel_subset)) \n",
    "\n",
    "                    print(\"parcel subset size: \", len(shared_parcel_subset))\n",
    "\n",
    "                    ############### LOSO Classification (Parcel Space) ############### \n",
    "\n",
    "                    # need to change dt to 'full' version if 'ss' in dt\n",
    "\n",
    "                    LOSO_parcel_results = {}\n",
    "\n",
    "                    for dt in dt_conditions_parcel:\n",
    "\n",
    "                        data_parcel = {}\n",
    "                        for subject in subjects:\n",
    "                            data_parcel[subject] = {}\n",
    "                            for run in data[subject]:\n",
    "                                if \"ss\" in dt:\n",
    "                                    if dt not in data[subject][run]['full']:\n",
    "                                        continue\n",
    "                                    data_parcel[subject][run] = data[subject][run]['full'][dt]\n",
    "                                else:\n",
    "                                    data_parcel[subject][run] = data[subject][run]['all_od']        \n",
    "\n",
    "                        all_parcel_features[dt] = all_parcel_features[dt] | get_parcel_loso_features(\n",
    "                            data=data_parcel,\n",
    "                            subjects=subjects,\n",
    "                            feature_types=feature_types,\n",
    "                            ft_slices=ft_slices,\n",
    "                            Adot=cfg.Adot,\n",
    "                            B=cfg.B,\n",
    "                            clean_ch_map=clean_ch_map,\n",
    "                            parcels=shared_parcel_subset,\n",
    "                            prune=prune_channels\n",
    "                        )\n",
    "\n",
    "                        parcel_features_by_dt[data_type][dt] = get_parcel_loso_features(\n",
    "                            data=data_parcel,\n",
    "                            subjects=subjects,\n",
    "                            feature_types=feature_types,\n",
    "                            ft_slices=ft_slices,\n",
    "                            Adot=cfg.Adot,\n",
    "                            B=cfg.B,\n",
    "                            clean_ch_map=clean_ch_map,\n",
    "                            parcels=shared_parcel_subset,\n",
    "                            prune=prune_channels\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport os\\nimport pickle\\nimport numpy as np\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\n\\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\\nfrom sklearn.metrics import accuracy_score\\nfrom sklearn.preprocessing import LabelEncoder\\nfrom sklearn.preprocessing import StandardScaler\\n\\nclassifiers = {\\n    \\'LDA\\': LinearDiscriminantAnalysis(solver=\\'lsqr\\', shrinkage=\\'auto\\'),\\n    #\\'SVC_lin\\': SVC(kernel=\\'linear\\', probability=True, C=0.1),\\n}\\n\\nsave_plot = True\\n\\nprune_by_zeroing = True\\nn_reduced_feat_ws = 30\\nn_reduced_feat_loso = 30\\nspatial_scaling = 2\\ndatasets_path = \"/home/thomas/Dokumente/Master/Master_Thesis/datasets/\"\\n\\ndt_conditions_parcel = [\\n    \"all_od\", \\n    \"all_od_ss_mean_full\"\\n]\\n\\ndt_labels_parcel = {\\n    \"all_od\": \"Parcel No SS Correction\",\\n    \"all_od_ss_mean_full\": \"Parcel SS corrected\",\\n}\\n\\nall_parcel_features = {dtcp: {} for dtcp in dt_conditions_parcel}\\nparcel_features_by_dt = {dt: {dtcp: {} for dtcp in dt_conditions_parcel} for dt in data_types}\\n\\n# Main pipeline\\nfor data_type in data_types:\\n\\n    print(f\"\\nProcessing {data_type} dataset... \\n\")\\n\\n    cfg = dataset_configs[data_type]\\n    synthetic = cfg[\"synthetic\"]\\n    subjects = cfg[\"subjects\"]\\n    #subjects = subjects[0:2]  # For testing, only use the first subject\\n    base_path = cfg[\"base_path\"]\\n    ft_slices = cfg[\"feature_slices\"]\\n    long_chs = cfg[\"long_channels\"]\\n    probe_area = cfg[\"probe_area\"]\\n    with open(os.path.join(base_path, \\'subsets_data\\'), \\'rb\\') as file:\\n        subsets_data = pickle.load(file)\\n    subset_keys = list(reversed(subsets_data.keys()))\\n\\n    print(\"SUBSETS\")\\n    print(subsets_data)\\n\\n    clean_ch_map = {}\\n    for subject_idx, subject in enumerate(subjects):\\n        clean_ch_map[subject] = {}\\n        for run in range(cfg[\"n_runs\"](subject_idx)):\\n            clean_ch_map[subject][run] = {}\\n            with open(os.path.join(base_path, cfg[\"clean_channels_path\"](subject, run)), \\'rb\\') as f:\\n                clean_ch_map[subject][run][\\'parcel\\'] = pickle.load(f)\\n\\n    result_path = f\\'/home/thomas/Dokumente/Master/Master_Thesis/results/{data_type}/channel_space/\\'\\n\\n    for int_scaling in [\\'03\\']:\\n        data = {}\\n        for subject_idx, subject in enumerate(subjects):\\n            data[subject] = {}\\n            n_runs = cfg[\"n_runs\"](subject_idx)\\n            for run in range(n_runs):\\n                ep_path = cfg[\"epochs_labels_path\"](subject, run, int_scaling, spatial_scaling)\\n                print(os.path.join(base_path, ep_path))\\n                with open(os.path.join(base_path, ep_path), \\'rb\\') as f:\\n                    data[subject][run] = pickle.load(f)\\n\\n        for feature_types in [\\'Slope\\']:\\n\\n            print(f\"\\nFeature type: {feature_types} \\n\")\\n\\n            for prune_channels in [True]:\\n\\n                print(f\"\\nPruning channels: {prune_channels} \\n\")\\n\\n                for reduce_features in [False]:\\n\\n                    print(f\"\\nFeature reduction: {reduce_features} \\n\")\\n\\n                    ############### ---- PARCEL SPACE CLASSIFICATION (per subject) ############### \\n\\n                    full_channel_subset = subsets_data[\\'full\\'][\\'all\\']\\n\\n                    selected_Adot = cfg[\"Adot\"]\\n                    selected_B = cfg[\"B\"]\\n\\n                    if synthetic:\\n                        selected_channels_mask = np.isin(selected_Adot.channel.values, full_channel_subset)\\n                        selected_Adot = selected_Adot[selected_channels_mask,:]\\n                        selected_channels_mask_stacked = np.tile(selected_channels_mask, 2)\\n                        selected_B = selected_B[:, selected_channels_mask_stacked]\\n\\n\\n                    print(\"biggest subset size: \", len(full_channel_subset)) \\n\\n                    print(\"parcel subset size: \", len(shared_parcel_subset))\\n\\n                    ############### LOSO Classification (Parcel Space) ############### \\n\\n                    # need to change dt to \\'full\\' version if \\'ss\\' in dt\\n\\n                    LOSO_parcel_results = {}\\n\\n                    for dt in dt_conditions_parcel:\\n\\n                        data_parcel = {}\\n                        for subject in subjects:\\n                            data_parcel[subject] = {}\\n                            for run in data[subject]:\\n                                if \"ss\" in dt:\\n                                    if dt not in data[subject][run][\\'full\\']:\\n                                        continue\\n                                    data_parcel[subject][run] = data[subject][run][\\'full\\'][dt]\\n                                else:\\n                                    data_parcel[subject][run] = data[subject][run][\\'all_od\\']        \\n\\n                        all_parcel_features[dt] = all_parcel_features[dt] | get_parcel_loso_features(\\n                            data=data_parcel,\\n                            subjects=subjects,\\n                            feature_types=feature_types,\\n                            ft_slices=ft_slices,\\n                            Adot=cfg[\"Adot\"],\\n                            B=cfg[\"B\"],\\n                            clean_ch_map=clean_ch_map,\\n                            parcels=shared_parcel_subset,\\n                            prune=prune_channels\\n                        )\\n\\n                        parcel_features_by_dt[data_type][dt] = get_parcel_loso_features(\\n                            data=data_parcel,\\n                            subjects=subjects,\\n                            feature_types=feature_types,\\n                            ft_slices=ft_slices,\\n                            Adot=cfg[\"Adot\"],\\n                            B=cfg[\"B\"],\\n                            clean_ch_map=clean_ch_map,\\n                            parcels=shared_parcel_subset,\\n                            prune=prune_channels\\n                        )\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "classifiers = {\n",
    "    'LDA': LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto'),\n",
    "    #'SVC_lin': SVC(kernel='linear', probability=True, C=0.1),\n",
    "}\n",
    "\n",
    "save_plot = True\n",
    "\n",
    "prune_by_zeroing = True\n",
    "n_reduced_feat_ws = 30\n",
    "n_reduced_feat_loso = 30\n",
    "spatial_scaling = 2\n",
    "datasets_path = \"/home/thomas/Dokumente/Master/Master_Thesis/datasets/\"\n",
    "\n",
    "dt_conditions_parcel = [\n",
    "    \"all_od\", \n",
    "    \"all_od_ss_mean_full\"\n",
    "]\n",
    "\n",
    "dt_labels_parcel = {\n",
    "    \"all_od\": \"Parcel No SS Correction\",\n",
    "    \"all_od_ss_mean_full\": \"Parcel SS corrected\",\n",
    "}\n",
    "\n",
    "all_parcel_features = {dtcp: {} for dtcp in dt_conditions_parcel}\n",
    "parcel_features_by_dt = {dt: {dtcp: {} for dtcp in dt_conditions_parcel} for dt in data_types}\n",
    "\n",
    "# Main pipeline\n",
    "for data_type in data_types:\n",
    "\n",
    "    print(f\"\\nProcessing {data_type} dataset... \\n\")\n",
    "\n",
    "    cfg = dataset_configs[data_type]\n",
    "    synthetic = cfg[\"synthetic\"]\n",
    "    subjects = cfg[\"subjects\"]\n",
    "    #subjects = subjects[0:2]  # For testing, only use the first subject\n",
    "    base_path = cfg[\"base_path\"]\n",
    "    ft_slices = cfg[\"feature_slices\"]\n",
    "    long_chs = cfg[\"long_channels\"]\n",
    "    probe_area = cfg[\"probe_area\"]\n",
    "    with open(os.path.join(base_path, 'subsets_data'), 'rb') as file:\n",
    "        subsets_data = pickle.load(file)\n",
    "    subset_keys = list(reversed(subsets_data.keys()))\n",
    "\n",
    "    print(\"SUBSETS\")\n",
    "    print(subsets_data)\n",
    "\n",
    "    clean_ch_map = {}\n",
    "    for subject_idx, subject in enumerate(subjects):\n",
    "        clean_ch_map[subject] = {}\n",
    "        for run in range(cfg[\"n_runs\"](subject_idx)):\n",
    "            clean_ch_map[subject][run] = {}\n",
    "            with open(os.path.join(base_path, cfg[\"clean_channels_path\"](subject, run)), 'rb') as f:\n",
    "                clean_ch_map[subject][run]['parcel'] = pickle.load(f)\n",
    "\n",
    "    result_path = f'/home/thomas/Dokumente/Master/Master_Thesis/results/{data_type}/channel_space/'\n",
    "\n",
    "    for int_scaling in ['03']:\n",
    "        data = {}\n",
    "        for subject_idx, subject in enumerate(subjects):\n",
    "            data[subject] = {}\n",
    "            n_runs = cfg[\"n_runs\"](subject_idx)\n",
    "            for run in range(n_runs):\n",
    "                ep_path = cfg[\"epochs_labels_path\"](subject, run, int_scaling, spatial_scaling)\n",
    "                print(os.path.join(base_path, ep_path))\n",
    "                with open(os.path.join(base_path, ep_path), 'rb') as f:\n",
    "                    data[subject][run] = pickle.load(f)\n",
    "\n",
    "        for feature_types in ['Slope']:\n",
    "\n",
    "            print(f\"\\nFeature type: {feature_types} \\n\")\n",
    "\n",
    "            for prune_channels in [True]:\n",
    "\n",
    "                print(f\"\\nPruning channels: {prune_channels} \\n\")\n",
    "\n",
    "                for reduce_features in [False]:\n",
    "\n",
    "                    print(f\"\\nFeature reduction: {reduce_features} \\n\")\n",
    "\n",
    "                    ############### ---- PARCEL SPACE CLASSIFICATION (per subject) ############### \n",
    "\n",
    "                    full_channel_subset = subsets_data['full']['all']\n",
    "\n",
    "                    selected_Adot = cfg[\"Adot\"]\n",
    "                    selected_B = cfg[\"B\"]\n",
    "\n",
    "                    if synthetic:\n",
    "                        selected_channels_mask = np.isin(selected_Adot.channel.values, full_channel_subset)\n",
    "                        selected_Adot = selected_Adot[selected_channels_mask,:]\n",
    "                        selected_channels_mask_stacked = np.tile(selected_channels_mask, 2)\n",
    "                        selected_B = selected_B[:, selected_channels_mask_stacked]\n",
    "\n",
    "\n",
    "                    print(\"biggest subset size: \", len(full_channel_subset)) \n",
    "\n",
    "                    print(\"parcel subset size: \", len(shared_parcel_subset))\n",
    "\n",
    "                    ############### LOSO Classification (Parcel Space) ############### \n",
    "\n",
    "                    # need to change dt to 'full' version if 'ss' in dt\n",
    "\n",
    "                    LOSO_parcel_results = {}\n",
    "\n",
    "                    for dt in dt_conditions_parcel:\n",
    "\n",
    "                        data_parcel = {}\n",
    "                        for subject in subjects:\n",
    "                            data_parcel[subject] = {}\n",
    "                            for run in data[subject]:\n",
    "                                if \"ss\" in dt:\n",
    "                                    if dt not in data[subject][run]['full']:\n",
    "                                        continue\n",
    "                                    data_parcel[subject][run] = data[subject][run]['full'][dt]\n",
    "                                else:\n",
    "                                    data_parcel[subject][run] = data[subject][run]['all_od']        \n",
    "\n",
    "                        all_parcel_features[dt] = all_parcel_features[dt] | get_parcel_loso_features(\n",
    "                            data=data_parcel,\n",
    "                            subjects=subjects,\n",
    "                            feature_types=feature_types,\n",
    "                            ft_slices=ft_slices,\n",
    "                            Adot=cfg[\"Adot\"],\n",
    "                            B=cfg[\"B\"],\n",
    "                            clean_ch_map=clean_ch_map,\n",
    "                            parcels=shared_parcel_subset,\n",
    "                            prune=prune_channels\n",
    "                        )\n",
    "\n",
    "                        parcel_features_by_dt[data_type][dt] = get_parcel_loso_features(\n",
    "                            data=data_parcel,\n",
    "                            subjects=subjects,\n",
    "                            feature_types=feature_types,\n",
    "                            ft_slices=ft_slices,\n",
    "                            Adot=cfg[\"Adot\"],\n",
    "                            B=cfg[\"B\"],\n",
    "                            clean_ch_map=clean_ch_map,\n",
    "                            parcels=shared_parcel_subset,\n",
    "                            prune=prune_channels\n",
    "                        )\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['sub-170', 'sub-173', 'sub-174', 'sub-176', 'sub-177', 'sub-179', 'sub-181', 'sub-182', 'sub-183', 'sub-185', 'sub-577', 'sub-580', 'sub-586', 'sub-587', 'sub-592', 'sub-613', 'sub-618', 'sub-619', 'sub-621', 'sub-633', 'sub-638', 'sub-640'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_parcel_features['all_od'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    'LDA': LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto'),\n",
    "    'Linear SVM': SVC(kernel='linear', C=0.1, max_iter=10000),\n",
    "    'RBF SVM': SVC(kernel='rbf', C=0.1, gamma='scale'),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42),\n",
    "    'MLP' : MLPClassifier(hidden_layer_sizes=(50, 20), max_iter=1000, early_stopping=True, random_state=69),\n",
    "}\n",
    "#classifier = classifiers[\"LDA\"]\n",
    "classifier = classifiers[\"Linear SVM\"]\n",
    "#classifier = classifiers[\"RBF SVM\"]\n",
    "#classifier = classifiers[\"Random Forest\"]\n",
    "#classifier = classifiers[\"MLP\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X ALL:\n",
      "(498, 104)\n",
      "4.898399959027884e-09\n",
      "X ALL:\n",
      "(498, 104)\n",
      "3.3998824493825618e-09\n",
      "X ALL:\n",
      "(900, 104)\n",
      "1.576239517520676e-09\n",
      "X ALL:\n",
      "(900, 104)\n",
      "1.5592138586758084e-09\n"
     ]
    }
   ],
   "source": [
    "results_loso_laura =  loso_classification(parcel_features_by_dt['BS_Laura']['all_od'], list(parcel_features_by_dt['BS_Laura']['all_od'].keys()), classifier)\n",
    "results_loso_ss_laura =  loso_classification(parcel_features_by_dt['BS_Laura']['all_od_ss_mean_full'], list(parcel_features_by_dt['BS_Laura']['all_od'].keys()), classifier)\n",
    "\n",
    "results_loso_hdsq =  loso_classification(parcel_features_by_dt['HD_Squeezing']['all_od'], list(parcel_features_by_dt['HD_Squeezing']['all_od'].keys()), classifier)\n",
    "results_loso_ss_hdsq =  loso_classification(parcel_features_by_dt['HD_Squeezing']['all_od_ss_mean_full'], list(parcel_features_by_dt['HD_Squeezing']['all_od'].keys()), classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HD_Squeezing\n",
      "0.7633333333333334\n",
      "0.7899999999999999\n",
      "BS Laura\n",
      "0.7327039583137144\n",
      "0.7906569461447511\n",
      "All (mean acc)\n",
      "0.7466264015044503\n",
      "0.7903583342607732\n"
     ]
    }
   ],
   "source": [
    "print(\"HD_Squeezing\")\n",
    "print(np.mean(list(results_loso_hdsq.values())))\n",
    "print(np.mean(list(results_loso_ss_hdsq.values())))\n",
    "print(\"BS Laura\")\n",
    "print(np.mean(list(results_loso_laura.values())))\n",
    "print(np.mean(list(results_loso_ss_laura.values())))\n",
    "print(\"All (mean acc)\")\n",
    "print(np.mean(list(results_loso_laura.values()) + list(results_loso_hdsq.values())))\n",
    "print(np.mean(list(results_loso_ss_laura.values()) + list(results_loso_ss_hdsq.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on pooled / combined data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X ALL:\n",
      "(1398, 104)\n",
      "2.75967006106187e-09\n",
      "X ALL:\n",
      "(1398, 104)\n",
      "2.214902669957613e-09\n"
     ]
    }
   ],
   "source": [
    "results_loso =  loso_classification(all_parcel_features['all_od'], list(all_parcel_features['all_od'].keys()), classifier, False, 30)\n",
    "results_loso_ss =  loso_classification(all_parcel_features['all_od_ss_mean_full'], list(all_parcel_features['all_od'].keys()), classifier, False, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sub-170', 'sub-173', 'sub-174', 'sub-176', 'sub-177', 'sub-179', 'sub-181', 'sub-182', 'sub-183', 'sub-185', 'sub-577', 'sub-580', 'sub-586', 'sub-587', 'sub-592', 'sub-613', 'sub-618', 'sub-619', 'sub-621', 'sub-633', 'sub-638', 'sub-640']\n",
      "[0.7666666666666667, 0.7777777777777778, 0.6222222222222222, 0.7777777777777778, 0.6333333333333333, 0.7111111111111111, 0.7444444444444445, 0.8666666666666667, 0.7, 0.9777777777777777, 0.5952380952380952, 0.5853658536585366, 0.8809523809523809, 0.8333333333333334, 0.5714285714285714, 0.6190476190476191, 0.8095238095238095, 0.7857142857142857, 0.7142857142857143, 0.8095238095238095, 0.7027027027027027, 0.6666666666666666]\n"
     ]
    }
   ],
   "source": [
    "print(list(all_parcel_features['all_od'].keys()))\n",
    "print(list(results_loso.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HD Squeezing\n",
      "0.7577777777777779\n",
      "0.768888888888889\n",
      "BS Laura\n",
      "0.7144819035062938\n",
      "0.758862521057643\n",
      "All\n",
      "0.7341618463569684\n",
      "0.7634199609809366\n"
     ]
    }
   ],
   "source": [
    "print(\"HD Squeezing\")\n",
    "print(np.mean(list(results_loso.values())[:10]))\n",
    "print(np.mean(list(results_loso_ss.values())[:10]))\n",
    "print(\"BS Laura\")\n",
    "print(np.mean(list(results_loso.values())[10:]))\n",
    "print(np.mean(list(results_loso_ss.values())[10:]))\n",
    "print(\"All\")\n",
    "print(np.mean(list(results_loso.values())))\n",
    "print(np.mean(list(results_loso_ss.values())))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unseen dataset classifcation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_on_all(all_data, subjects, clf, scaler, fit_clf=True):\n",
    "    # either train or test classifier on whole dataset - used for unseen dataset classification\n",
    "    X_all, y_all, subj_idx = [], [], []\n",
    "    for i, subject in enumerate(subjects):\n",
    "        for X, y in all_data[subject]:  # each run already processed to X, y\n",
    "            X_all.append(X)\n",
    "            y_all.append(y)\n",
    "            subj_idx += [i] * len(y)\n",
    "\n",
    "    X_all = np.vstack(X_all)\n",
    "    y_all = np.concatenate(y_all)\n",
    "    subj_idx = np.array(subj_idx)\n",
    "\n",
    "    if fit_clf:\n",
    "        X_all = scaler.fit_transform(X_all)\n",
    "        clf.fit(X_all, y_all)\n",
    "        results = None\n",
    "    else: \n",
    "        X_all = scaler.transform(X_all)\n",
    "        y_pred = clf.predict(X_all)\n",
    "        \n",
    "        # Compute accuracy per subject\n",
    "        results = {}\n",
    "        for i, subject in enumerate(subjects):\n",
    "            idx = subj_idx == i\n",
    "            acc = accuracy_score(y_all[idx], y_pred[idx])\n",
    "            results[subject] = acc\n",
    "\n",
    "    return results, clf, scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important: don't reuse one classifier object but define new one with every function call so the saved fitted classifier objects don't get manipulated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_all_hd_sq, clf_all_hd_sq, scaler_all_hd_sq = classify_on_all(parcel_features_by_dt['HD_Squeezing']['all_od'], parcel_features_by_dt['HD_Squeezing']['all_od'].keys(), SVC(kernel='linear', C=0.1, max_iter=10000), StandardScaler(), fit_clf=True)\n",
    "results_all_ss_hd_sq, clf_all_ss_hd_sq, scaler_all_ss_hd_sq = classify_on_all(parcel_features_by_dt['HD_Squeezing']['all_od_ss_mean_full'], parcel_features_by_dt['HD_Squeezing']['all_od'].keys(), SVC(kernel='linear', C=0.1, max_iter=10000), StandardScaler(), fit_clf=True)\n",
    "\n",
    "results_unseen_laura, _, __ = classify_on_all(parcel_features_by_dt['BS_Laura']['all_od'], parcel_features_by_dt['BS_Laura']['all_od'].keys(), clf_all_hd_sq, scaler_all_hd_sq, fit_clf=False)\n",
    "results_unseen_ss_laura, _, __ =  classify_on_all(parcel_features_by_dt['BS_Laura']['all_od_ss_mean_full'], parcel_features_by_dt['BS_Laura']['all_od'].keys(), clf_all_ss_hd_sq, scaler_all_ss_hd_sq, fit_clf=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sub-577': 0.38095238095238093, 'sub-580': 0.6341463414634146, 'sub-586': 0.5952380952380952, 'sub-587': 0.7142857142857143, 'sub-592': 0.4523809523809524, 'sub-613': 0.6666666666666666, 'sub-618': 0.6190476190476191, 'sub-619': 0.6190476190476191, 'sub-621': 0.5, 'sub-633': 0.7857142857142857, 'sub-638': 0.8378378378378378, 'sub-640': 0.5714285714285714}\n",
      "0.6147288403385964\n",
      "{'sub-577': 0.35714285714285715, 'sub-580': 0.7073170731707317, 'sub-586': 0.8809523809523809, 'sub-587': 0.7619047619047619, 'sub-592': 0.5476190476190477, 'sub-613': 0.7857142857142857, 'sub-618': 0.7380952380952381, 'sub-619': 0.6904761904761905, 'sub-621': 0.7619047619047619, 'sub-633': 0.9761904761904762, 'sub-638': 0.7837837837837838, 'sub-640': 0.6666666666666666}\n",
      "0.7214806269684318\n"
     ]
    }
   ],
   "source": [
    "print(results_unseen_laura)\n",
    "print(np.mean(list(results_unseen_laura.values())))\n",
    "print(results_unseen_ss_laura)\n",
    "print(np.mean(list(results_unseen_ss_laura.values())))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cedalion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
